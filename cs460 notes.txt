book for class: Machine Learning Tom Mitchell

grading
projects 40% 4 for 10 each
midterm 30%
non-cumulative final 30%

machine learning - the study of algorithms that improves their performance P at some task T with experience E.
p - desired outcome
T - task
E - given data
performance is related to the desired outcome of an event. ie. win chess, accurately diagnose, identify groups.

supervised learning - training data includes expected output
unsupervised learning - training data does not include expected output.



attributes - features
prediction - class (label)
preprocessing is often needed.
x1, x2 etc - a single training example
X: - set of all possible combinations of features
F:X->Y - target concept
H: - set of all hypotheses that the learner may consider regarding the identity of F
goal of the learner - find h within H such that h(x) == f(x) (the right hypothesis) for all xi in X.
if y is discrete, it is called a classification task
if y is continuous, it is called a regression task

model representations - supervised learning
 decision trees
 neural networks
 support vector machines (SVM)
 Bayesian networks

representations with unsupervised learning - discover pattern in the data
 data without labels?
 clustering
 

probability = # times event occurs/total trials
sample space - set of all possible outcomes of an event
P(a|B) = P(A && B)/P(B)
P(x1,x2,x3,x4) = P(x1|others)P(x2|x3,x4)P(x3|x4)P(x4)
P(A || B) = P(A) + P(B) - P(A,B)
gradient descent better when used with higher dimensional space.
 minimize sum of squared errors..... derive SSE/2, calculate partial derivative with M, get vector.
 something something put a negative on the vector to get the steepest decrease..?
  gradient of F(x,y) = [partial deriv x, partial deriv y] if f(x,y) = x+3y^2, gradient = [1,6y]
   so applying a point to the negative of the gradient, you get closer to minimum.
   
sum of squared error = the sum((actualData - predictedValue)^2)

concept learning - infer a concept by learning from past experiences
inductive learning hypothesis - READ CHAPTER 2 BECAUSE WHAT THE HELL IS THIS.

attributes have various values. introduce new value ? meaning that any value is okay.

given hi and hj, hi is more general than or rqual to hj (hi >= hj) if and only if all possibilities of hj are contained within hi...........
A ? ?   h1
? B ?   h3
h1 !>= h3, h3 !>= h1

find-s algorithm - make a hypothesis to match the first data point, then check every other positive data point and generalize
 the hypothesis with each one. this is a pretty bad algorithm.
 it can predict known failures as positive.
  this algorithm finds the h: <sunny, warm, ?, Strong, ?, ?>, which could be one of 6. itself, one of the 3 pairs, or one of the singles.
 if 2 of 3 options are found, then no hypothesis can explain the data. BUT A ? IS STILL USED TO SHOW IT. THATS STUPID.
 conditions - there are no training errors (aka impossible on real data), there exists a hypothesis that can explains the target concept
 weaknesses - only finds single hypothesis when there could be more, breaks if training errors exist, only finds single hypothesis

candidate elimination algorithm - finds all potential hypotheses that can match the data?
 version space - VSh,d = {h in H | consistent(h,D)} the version space is the set of all hypotheses consistent with training data.
 start with the empty set as the marker for most specific, all ? hypothesis for most general.
  most specific will follow find-S algorithm, 
  most general will include a number of hypotheses, each focusing on a single attribute's value. the possibilities are then limited
   based on what is allowed from the most specific hypothesis. constant checking between them is needed.
   <sunny,warm,?,strong,warm,same> is S3
   <sunny ?????>, <?warm?????><?????same> is G
    next iteration changes same from s3 into a ?, thus the third hypothesis in G must be removed because it is now inconsistent with the data.
 conditions - there can not be any training errors, can be explained by a set of hypotheses.
 using results - all yes, positive.   majority yes, positive, even or more fail, negative.

decision tree - learning by inductive inference that is much more widely used than what we covered in concept leaning
 robust to noisy data, search a more expressive hypothesis space.
 learned function is represented as a decision tree, classification label usually discrete values, can be continuous
 used to classify patients by disease, find cause of equipment malfunctions, assess credit risk of loan applicants.
core algorithm known as ID3 (uses entropy and information gain to construct tree)
 'intuition' explains that the more an attribute is able to determine the classification outcome by itself, the higher up it should be.
  information gain is the measure of how well a given attribute determines the classification.
  entropy is used to measure the degree of similarity
   entropy - how pure something is. 
Entropy(s) = -P+*log(P+) - P-*log(P-)    P+ = probability value is positive.  log is base 2.
    min = 0 at only pos/neg.   max = 1 at 50% each
information gain - measures reduction in entropy caused by partitioning training examples based on A
gain(S,A) = Entropy(S) - SIGMA(v in Values(A))(|Sv|*Entropy(Sv)/|S|) this formula is a fucking mess...
          = Entropy(S) - (Sv1/S*Entropy(Sv) + 
 
gain(S,wind)=entropy(S)-(|Sweak|/|S| * entropy(Sweak) + |Sstrong|/|S| * entropy (Sstrong))
 14 entries, strong/yes 3   strong/no 3   weak/yes 6  weak/no 2  
 total strong 6  total weak 8  total yes 9   total no 5

 entropy(S) = -9/14*log(9/14) - 5/14 * log(5/14) = .94ish
 gain = .94 - (6/14 * entropy(Sstrong) + 8/14 * entropy(Sweak))
		      -3/6 * log(3/6) - 3/6*log(3/6)          -6/8*log(6/8) - 2/8*log(2/8)
 = .94 - (6/14*(-3/6 * log(3/6) - 3/6*log(3/6)) + 8/14*( -6/8*log(6/8) - 2/8*log(2/8)))

weakness - doesn't backtrack, but does it need to?

S = sample space of given attribute
A = set potential values of attribute

Entropy(S) = -(prob pos (total yes/total))*log(prob pos)) - (prob neg(total no/total))*log(prob neg))
gain(S,A) = Entropy(S) - {prob S has Ai(total strong/total) * Entropy(S with Ai)} SUMMED FOR ALL Ai
 Entropy(S with Ai) = -(prob+((strong/yes / total strong)3/6)log(prob+(3/6)) -(prob-(3/6)log(prob-(3/6))

entropy(S) = total entropy in table
gain(S,A) = current entropy minus the sum of the entropy found within each possible value of the attribute
 if the entropy within the sum of potential values is significantly smaller than the original entropy, then they should be split up to
  reduce the total entropy in the table. THE VALUE WITH THE HIGHEST GAIN VALUE IS THE BEST OPTION FOR THE ROOT NODE OF A SPLIT.


After going down a branch, S becomes SAi (ie Ssunny on the sunny path)

inductive bias - assumptions regarding the hypothesis and training data allow us to generalize over unseen examples.
bias favors smaller trees?
approximate bias - shorter trees are preferred over larger ones.
Occam's razor - choosing the simplest way to describe why something happens when multiple hypotheses are present.

with training data, overfitting increases accuracy (for obvious reasons)
with real data, accuracy falls once too many nodes are made. peaks at 5, drops around 20, progressively gets worse (in one study)

binning - giving ranges for continuous values to partition them into a manageable number of potential values.
strategies to fill in blank values - 
 choose most common value for that attribute
 choose most common value for that attribute and class label (y/n)
 fill in as probabilities based on previous values.


















