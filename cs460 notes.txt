book for class: Machine Learning Tom Mitchell

grading
projects 40% 4 for 10 each
midterm 30%
non-cumulative final 30%

machine learning - the study of algorithms that improves their performance P at some task T with experience E.
p - desired outcome
T - task
E - given data
performance is related to the desired outcome of an event. ie. win chess, accurately diagnose, identify groups.

supervised learning - training data includes expected output
unsupervised learning - training data does not include expected output.



attributes - features
prediction - class (label)
preprocessing is often needed.
x1, x2 etc - a single training example
X: - set of all possible combinations of features
F:X->Y - target concept
H: - set of all hypotheses that the learner may consider regarding the identity of F
goal of the learner - find h within H such that h(x) == f(x) (the right hypothesis) for all xi in X.
if y is discrete, it is called a classification task
if y is continuous, it is called a regression task

model representations - supervised learning
 decision trees
 neural networks
 support vector machines (SVM)
 Bayesian networks

representations with unsupervised learning - discover pattern in the data
 data without labels?
 clustering
 

probability = # times event occurs/total trials
sample space - set of all possible outcomes of an event
P(a|B) = P(A && B)/P(B)
P(x1,x2,x3,x4) = P(x1|others)P(x2|x3,x4)P(x3|x4)P(x4)
P(A || B) = P(A) + P(B) - P(A,B)
gradient descent better when used with higher dimensional space.
 minimize sum of squared errors..... derive SSE/2, calculate partial derivative with M, get vector.
 something something put a negative on the vector to get the steepest decrease..?
  gradient of F(x,y) = [partial deriv x, partial deriv y] if f(x,y) = x+3y^2, gradient = [1,6y]
   so applying a point to the negative of the gradient, you get closer to minimum.
   
sum of squared error = the sum((actualData - predictedValue)^2)

concept learning - infer a concept by learning from past experiences
inductive learning hypothesis - READ CHAPTER 2 BECAUSE WHAT THE HELL IS THIS.

attributes have various values. introduce new value ? meaning that any value is okay.

given hi and hj, hi is more general than or rqual to hj (hi >= hj) if and only if all possibilities of hj are contained within hi...........
A ? ?   h1
? B ?   h3
h1 !>= h3, h3 !>= h1

find-s algorithm - make a hypothesis to match the first data point, then check every other positive data point and generalize
 the hypothesis with each one. this is a pretty bad algorithm.
 it can predict known failures as positive.
  this algorithm finds the h: <sunny, warm, ?, Strong, ?, ?>, which could be one of 6. itself, one of the 3 pairs, or one of the singles.
 if 2 of 3 options are found, then no hypothesis can explain the data. BUT A ? IS STILL USED TO SHOW IT. THATS STUPID.
 conditions - there are no training errors (aka impossible on real data), there exists a hypothesis that can explains the target concept
 weaknesses - only finds single hypothesis when there could be more, breaks if training errors exist, only finds single hypothesis

candidate elimination algorithm - finds all potential hypotheses that can match the data?
 version space - VSh,d = {h in H | consistent(h,D)} the version space is the set of all hypotheses consistent with training data.
 start with the empty set as the marker for most specific, all ? hypothesis for most general.
  most specific will follow find-S algorithm, 
  most general will include a number of hypotheses, each focusing on a single attribute's value. the possibilities are then limited
   based on what is allowed from the most specific hypothesis. constant checking between them is needed.
   <sunny,warm,?,strong,warm,same> is S3
   <sunny ?????>, <?warm?????><?????same> is G
    next iteration changes same from s3 into a ?, thus the third hypothesis in G must be removed because it is now inconsistent with the data.
 conditions - there can not be any training errors, can be explained by a set of hypotheses.
 using results - all yes, positive.   majority yes, positive, even or more fail, negative.

decision tree - learning by inductive inference that is much more widely used than what we covered in concept leaning
 robust to noisy data, search a more expressive hypothesis space.
 learned function is represented as a decision tree, classification label usually discrete values, can be continuous
 used to classify patients by disease, find cause of equipment malfunctions, assess credit risk of loan applicants.
core algorithm known as ID3 (uses entropy and information gain to construct tree)
 'intuition' explains that the more an attribute is able to determine the classification outcome by itself, the higher up it should be.
  information gain is the measure of how well a given attribute determines the classification.
  entropy is used to measure the degree of similarity
   entropy - how pure something is. Entropy(s) = -P+*log(P+) - P-*log(P-)    P+ = probability value is positive.  log is base 2.
    min = 0 at only pos/neg.   max = 1 at 50% each
information gain - measures reduction in entropy caused by partitioning training examples based on A
 gain(S,A) = Entropy(S) - SIGMA(v in Values(A))(|Sv|*Entropy(Sv)/|S|) this formula is a fucking mess...
 
gain(S,wind)=entropy(S)-(|Sweak|/|S| * entropy(Sweak) + |Sstrong|/|S| * entropy (Sstrong))




























